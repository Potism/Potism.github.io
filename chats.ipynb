{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMgsu9JoU1DJ2a6Yfc28nNK",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Potism/Potism.github.io/blob/main/chats.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qvif8pOmHJkQ"
      },
      "outputs": [],
      "source": [
        "!pip install -q llama-index\n",
        "!pip install -q cohere\n",
        "!pip install -q transformers\n",
        "!pip install -q accelerate"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q openai\n",
        "!pip install -q pypdf\n",
        "!pip install sentence_transformers -q"
      ],
      "metadata": {
        "id": "xdVnD6XrKdLM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8845ab7d-77c4-4f7a-f7cd-b757d8e152cf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m48.2/48.2 kB\u001b[0m \u001b[31m1.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.7/2.7 MB\u001b[0m \u001b[31m35.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m277.4/277.4 kB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "os.environ[\"OPENAI_API_KEY\"] = \"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\"\n",
        "\n",
        "from llama_index.llms import OpenAI\n",
        "from llama_index import VectorStoreIndex, SimpleDirectoryReader\n",
        "from IPython.display import Markdown, display\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "Et1TP3xkeEoS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "documents = SimpleDirectoryReader(\"data\").load_data()"
      ],
      "metadata": {
        "id": "WM6VEk4-6v0_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "index = VectorStoreIndex.from_documents(documents)"
      ],
      "metadata": {
        "id": "7JZMU0GX6w88"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "query_engine = index.as_query_engine()\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "li9TmOtsSAqN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "response = query_engine.query(\"on which technology exisiting models are working?\")\n"
      ],
      "metadata": {
        "id": "lg5j_YrOswul"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "display(Markdown(f\"<b>{response}</b>\"))"
      ],
      "metadata": {
        "id": "1PJTvo_ahruI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "index.storage_context.persist()"
      ],
      "metadata": {
        "id": "Na_iETlXBh9o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from llama_index import StorageContext, load_index_from_storage\n",
        "\n",
        "storage_context = StorageContext.from_defaults(persist_dir=\"./storage\")\n",
        "index = load_index_from_storage(storage_context=storage_context)"
      ],
      "metadata": {
        "id": "7Sn7SF9bBxYu"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}